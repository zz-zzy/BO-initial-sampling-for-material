{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc236e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "# import emukit\n",
    "import GPy\n",
    "# from emukit.core import ParameterSpace, ContinuousParameter, DiscreteParameter\n",
    "# from emukit.core.initial_designs.random_design import RandomDesign\n",
    "# from emukit.core.initial_designs.latin_design import LatinDesign\n",
    "from GPy.models import GPRegression\n",
    "from emukit.model_wrappers import GPyModelWrapper\n",
    "\n",
    "# from emukit.bayesian_optimization.loops import BayesianOptimizationLoop\n",
    "from emukit.bayesian_optimization.acquisitions import ExpectedImprovement, \\\n",
    "                                                      NegativeLowerConfidenceBound, \\\n",
    "                                                      MaxValueEntropySearch, \\\n",
    "                                                      ProbabilityOfImprovement\n",
    "# from emukit.core.acquisition import IntegratedHyperParameterAcquisition\n",
    "\n",
    "from rgpe import compute_rank_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed0a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from emukit.core.initial_designs.latin_design import LatinDesign\n",
    "\n",
    "def find_y_by_x(x_input, X_all, Y_all):  #一通过x找到对应的y的函数\n",
    "    # 确保 x_input 是一个二维数组\n",
    "    if len(x_input.shape) == 1:\n",
    "        x_input = x_input.reshape(1, -1)\n",
    "\n",
    "    # 初始化一个列表来存储所有结果\n",
    "    all_results = []\n",
    "\n",
    "    # 遍历 x_input 中的每个特征向量\n",
    "    for x in x_input:\n",
    "        # 使用 NumPy 的函数 argwhere 来查找 x 在 X 中的位置\n",
    "        indices = np.argwhere(np.all(X_all == x, axis=1))\n",
    "\n",
    "        # 初始化一个列表来存储匹配的 Y 值\n",
    "        matching_y_values = []\n",
    "\n",
    "        # 遍历匹配的位置\n",
    "        for index in indices:\n",
    "            match_index = index[0]\n",
    "            matching_y_values.append(Y_all[match_index])\n",
    "\n",
    "        all_results.append(matching_y_values)\n",
    "    \n",
    "    all_results = np.array(all_results)\n",
    "    return all_results\n",
    "\n",
    "def x_normalizer(X, var_array):\n",
    "    \n",
    "    def max_min_scaler(x, x_max, x_min):\n",
    "        return (x-x_min)/(x_max-x_min)\n",
    "    x_norm = []\n",
    "    for x in (X):\n",
    "           x_norm.append([max_min_scaler(x[i], \n",
    "                                         max(var_array[i]), \n",
    "                                         min(var_array[i])) for i in range(len(x))])\n",
    "            \n",
    "    return x_norm\n",
    "\n",
    "def x_denormalizer(x_norm, var_array):\n",
    "    \n",
    "    def max_min_rescaler(x, x_max, x_min):\n",
    "        return x*(x_max-x_min)+x_min\n",
    "    x_original = []\n",
    "    for x in (x_norm):\n",
    "           x_original.append([max_min_rescaler(x[i], \n",
    "                                         max(var_array[i]), \n",
    "                                         min(var_array[i])) for i in range(len(x))])\n",
    "            \n",
    "    return x_original\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def get_closest_array(x_init, X_all):\n",
    "#     # 计算 x_init 中每个点与 X_all 中所有点之间的距离\n",
    "#     distances = cdist(x_init, X_all)   \n",
    "#     # 找到每个点最近的索引\n",
    "#     closest_indices = np.argmin(distances, axis=1)    \n",
    "#     # 根据索引获取最近的点\n",
    "#     closest_array = X_all[closest_indices]  \n",
    "#     return closest_array\n",
    "\n",
    "def get_closest_array(x_init, X_all):\n",
    "    X_all_copy = X_all.copy()\n",
    "    closest_array = []\n",
    "    \n",
    "    for x in x_init:\n",
    "        # 计算 x 与 X_all_copy 中所有点之间的距离\n",
    "        distances = cdist([x], X_all_copy)[0]\n",
    "        # 找到最近的索引\n",
    "        closest_index = np.argmin(distances)\n",
    "        # 根据索引获取最近的点\n",
    "        closest_point = X_all_copy[closest_index]\n",
    "        # 将最近的点添加到结果数组中\n",
    "        closest_array.append(closest_point)\n",
    "        # 从 X_all_copy 中移除这个点\n",
    "        X_all_copy = np.delete(X_all_copy, closest_index, axis=0)\n",
    "        \n",
    "    return np.array(closest_array)\n",
    "\n",
    "\n",
    "# # 计算两个点之间的欧几里得距离\n",
    "# def euclidean_distance(point1, point2):\n",
    "#     return np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "\n",
    "# # 找到X_all中与x_init每个元素最近的点\n",
    "# def get_closest_array(x_init, X_all):\n",
    "#     closest_array = []\n",
    "#     for point in x_init:\n",
    "#         distances = np.array([euclidean_distance(point, x) for x in X_all])\n",
    "#         closest_idx = distances.argmin()\n",
    "#         closest_array.append(X_all[closest_idx])\n",
    "#     return np.array(closest_array)\n",
    "\n",
    "def create_latin_design(X_all):\n",
    " \n",
    "    x_array = [X_all[:, i] for i in range(X_all.shape[1])]\n",
    "    \n",
    "    num_columns = X_all.shape[1]\n",
    "    parameter_space = ParameterSpace([ContinuousParameter(f'x{i+1}', 0, 1) for i in range(num_columns)])\n",
    "    design = LatinDesign(parameter_space)\n",
    "    \n",
    "    return x_array , design\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a9779",
   "metadata": {},
   "source": [
    "# 导入目标任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39af1db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 10)\n",
      "(88, 9) (88,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# folder_path = r'C:\\Users\\13282\\Desktop\\papercode\\data\\Goldstein' \n",
    "# file_path = os.path.join(folder_path, 'goldstein_data.xlsx')\n",
    "\n",
    "folder_path = r'C:\\Users\\13282\\Desktop\\papercode\\data\\Alloy\\matminner_processed' \n",
    "file_path = os.path.join(folder_path, 'Ti.xlsx')  # y 记得加负号 ，如果需要原始值，需要反log回去\n",
    "\n",
    "# Virtual_ti\n",
    "\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "#去除存在nan的点\n",
    "# nan_indices = np.isnan(Y)\n",
    "# X = X[~nan_indices.flatten()]\n",
    "# Y = Y[~nan_indices.flatten()]\n",
    "print(df.shape)\n",
    "\n",
    "X_all = df.iloc[:, :-1].values  \n",
    "Y_all = - df.iloc[:, -1].values   \n",
    "\n",
    "print(X_all.shape,Y_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4109f289",
   "metadata": {},
   "source": [
    "# x和y预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78f2d41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 的索引: []\n",
      "(88, 9) (88,)\n",
      "-8.470101583882409 (array([6], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_all = min_max_scaler.fit_transform(X_all)\n",
    "\n",
    "#去除存在nan的点\n",
    "nan_indices = np.isnan(Y_all)\n",
    "true_indices = np.where(nan_indices)[0]\n",
    "print(\"nan 的索引:\", true_indices)\n",
    "\n",
    "X_all = X_all[~nan_indices.flatten()]\n",
    "Y_all = Y_all[~nan_indices.flatten()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30265d7b",
   "metadata": {},
   "source": [
    "# 导入源模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80f1caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# 定义要加载的模型名称列表\n",
    "\n",
    "# file_name = \"oth2\" \n",
    "# model_names_to_load = ['base_model_oth2.pkl']\n",
    "# folder_path = r'C:\\Users\\13282\\Desktop\\papercode\\trasfer\\base_model\\Goldstein' \n",
    "\n",
    "# Fe  Co  Ni  others  Co_plus\n",
    "model_names_to_load = ['Fe.pkl','Ni.pkl','Co_plus.pkl',]\n",
    "folder_path = r'C:\\Users\\13282\\Desktop\\papercode\\trasfer\\base_model\\Alloy\\matminer' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loaded_models = {}\n",
    "for model_name in model_names_to_load:\n",
    "    model_filename = os.path.join(folder_path, model_name)\n",
    "    with open(model_filename, 'rb') as f:\n",
    "        loaded_models[model_name] = pickle.load(f)\n",
    "base_models = []\n",
    "for model_name in model_names_to_load:\n",
    "    base_models.append(loaded_models[model_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a860100",
   "metadata": {},
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9b36bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 针对最优值点计算同增同减的对数\n",
    "\n",
    "def calculate_ratio(X_all, Y_all, model):\n",
    "    # 找到 Y_all 中的最小值及其索引\n",
    "    y_min = np.nanmin(Y_all)\n",
    "    indice = np.where(Y_all == y_min)\n",
    "    \n",
    "    # 使用模型进行预测\n",
    "    f_obj = model.predict\n",
    "    y_pred, y_uncer = f_obj(X_all)\n",
    "    y_pred = y_pred[:, -1]  # 假设只需要最后一列的预测值\n",
    "    \n",
    "    # 计算 truth 和 pred\n",
    "    truth = Y_all - y_min\n",
    "    pred = y_pred - y_pred[indice].flatten()  # flatten 以确保形状匹配\n",
    "    \n",
    "    # 计算乘积 c\n",
    "    c = truth * pred\n",
    "    \n",
    "    # 计算 c 中大于 0 的元素个数及其比例\n",
    "    count = np.sum(c > 0)\n",
    "    ratio = count / len(c)\n",
    "    ratio = round(ratio, 2)\n",
    "    \n",
    "    return ratio\n",
    "\n",
    "# 计算所有点同增同减的对数\n",
    "\n",
    "def roll_col(X: np.ndarray, shift: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rotate columns to right by shift.\n",
    "    \"\"\"\n",
    "    return np.concatenate((X[:, -shift:], X[:, :-shift]), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def compute_ranking_loss(\n",
    "    f_samps: np.ndarray,\n",
    "    target_y: np.ndarray,\n",
    "    target_model: bool,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute ranking loss for each sample from the posterior over target points.\n",
    "    \"\"\"\n",
    "    y_stack = np.tile(target_y.reshape((-1, 1)), f_samps.shape[0]).transpose()\n",
    "    rank_loss = np.zeros(f_samps.shape[0])\n",
    "    if not target_model:\n",
    "        for i in range(1, target_y.shape[0]):\n",
    "            rank_loss += np.sum(\n",
    "                (roll_col(f_samps, i) < f_samps) ^ (roll_col(y_stack, i) < y_stack),  #用矩阵滚动的形式，让每个数都进行了比较\n",
    "                axis=1\n",
    "            )\n",
    "    else:\n",
    "        for i in range(1, target_y.shape[0]):\n",
    "            rank_loss += np.sum(\n",
    "                (roll_col(f_samps, i) < y_stack) ^ (roll_col(y_stack, i) < y_stack),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "    return rank_loss\n",
    "\n",
    "def calculate_all_ratio(X_all, Y_all, model):\n",
    "    \n",
    "    f_obj = model.predict\n",
    "    y_pred, y_uncer = f_obj(X_all)\n",
    "    y_pred = y_pred[:, -1]\n",
    "    \n",
    "    rank_loss = compute_ranking_loss(y_pred.reshape(-1,1), Y_all.reshape(-1,1), False)\n",
    "    count = rank_loss[0]\n",
    "    all_count = len(rank_loss) * (len(rank_loss)-1)\n",
    "    ratio = count / all_count\n",
    "    ratio = round(ratio, 2)\n",
    "    \n",
    "    return ratio,count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c7c41c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6  0.55 0.56]\n"
     ]
    }
   ],
   "source": [
    "ratios = []\n",
    "\n",
    "for model in base_models:\n",
    "    ratio = calculate_ratio(X_all, Y_all, model.model)\n",
    "#     ratio ,count = calculate_all_ratio(X_all, Y_all, model.model)\n",
    "    \n",
    "    ratios.append(ratio)\n",
    "    \n",
    "\n",
    "ratios_array = np.array(ratios)\n",
    "print(ratios_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324558d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a040d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
